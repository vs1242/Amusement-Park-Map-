{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vs1242/Amusement_Park_Map/blob/main/Deep%20Learning%20for%20Image%20Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD7vN3qeJ5GI"
      },
      "source": [
        "**1)** PCA and NMF are techniques used for dimensionality reduction in that data is simplified without losing the important patterns.\n",
        "PCA is a transformation of the data to a new coordinate system such that each principal component is the axis along which the data set has maximum variance (the sum of squares of the deviations from the axis), calculated as linear combinations of the original features. It enforces the second moment of components as two orthogonal (uncorrelated) and can be used with any numerical data.\n",
        "NMF, on the other hand, decomposes non-negative data into two non-negative matrices: basis ùëä and coefficients H. The results of this approach are more interpretable since data is represented as additive combination of components. Similarities: Both explore the dimensionality, find the patterns and are unsupervised learning methods. The data is approximately modeled by linear transformations. Differences: It can handle all numerical data, orthogonal components and minimum variance based reconstruction error. Non negative data, orthogonality is not guaranteed, deals with additive parts based representation by trying to minimize divergence or error under non negativity constraints is NMF.\n",
        "\n",
        "To summarize, NMF is excelent for produce interpretable results for non-negative data, like texts or images and PCA is making variance and decorrelating features.\n",
        "\n",
        "---\n",
        "\n",
        "**2)**  Weights and biases of neural networks are to be initialized because they affect learning efficiency and performance. Symmetry breaking is assumed by proper weight initialization, one that prevents neurons in a layer from learning the same feature. In addition, it controls the gradient flow during backpropagation: making sure the gradient doesn't either explode or explode is essential to learning.\n",
        "\n",
        "Methods such as Xavier/Glorot or He initialization proportionally scales weights according to the number of neurons, thereby stabilizing gradient flow and accelerating the convergence leading to a closer solution to an optimal point. You typically use small constant biases (e.g. zero) which shift activations without breaking symmetry.\n",
        "\n",
        "It‚Äôs also good for reducing training time, and avoiding common pitfalls like slow convergence or getting stuck in bad regions of the loss landscape, and it helps the network learn effectively. Furthermore, initialization is the foundation required for achieving stable and efficient neural network training.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**3)** Accuracy in ANN is precluded from overfitting the to unseen data. For instance, regularization techniques such as L1/L2 penalties penalize large weights, while dropout randomly kills neurons during training so something else would jump in if too much was placed in that one neuron. Designing smaller architectures with fewer layers or neurons strikes a balance through controlling the model complexity and avoids excessive memorization. When the dataset size is increased through collection or augmentation (e.g., flipping, cropping, rotating) then the model learns from diverse set of examples. Validation loss is monitored early stopping and stops training when validation loss begins to increase, therefore, avoiding over fit. It stabilizes and regularizes activations during training. Moreover, cross-validation, e.g. kfold, is used for tuning hyperparameters and on the evaluation of the generalization. But with these techniques, ANNs are shown to perform robustly on both training and unseen data.\n",
        "\n",
        "\n",
        "---\n",
        "**4)** Feedforward Neural Networks are made up to two types, namely Convolutional Neural Networks (CNNs) and Multilayer Perceptrons (MLPs) but are different in structure and applications. CNNs are good for grid like input, things like images and videos, and you therefore take advantage of spatial hierarchies; you end up with convolutional layers that pull out local patterns, pooling layers that reduce dimensionality, and then fully connected layers that you use to do classification. On the other hand, MLPs are fully connected layers in which all features of input are treated equally without any consideration of the spatial relationships.  \n",
        "\n",
        "A key difference is **parameter sharing**: In a CNNs, they have weights shared in their convolutional layers that drastically decreases the number of parameters required and enables the detection of local features efficiently. Unlike parameter sharing, these parameter genders do not share parameters, thus producing a lot more weights.  \n",
        "\n",
        "CNNs are good for image classification and object detection type of tasks because features (edges, textures, etc.) are learned automatically (spatial) by them. While structured data like tabular data suits MLPs better than many other models and performs well on small scale problems, MLPs are less preferred than many other models for problems with unstructured data. In general, CNN do best at tasks involving spatial dependencies, while MLPs are more generally useful models.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**5)** In particular, **vanishing gradient problem** is caused in neural networks, a lot especially using **sigmoid activation functions**. This is the issue regarding the fact that the gradients, which are being calculated during backpropagation, become very small as the gradients are propagated backwards through the network. This is because the derivative of sigmoid function is close to zero for a large positive or negative input. This means that the gradients for these inputs become small, so that the weights in earlier layers update very slowly and it **learns slowly** or **the training stalls**.  \n",
        "\n",
        "The problem gets worse as we go deeper into the networks as gradients are multiplied through multiple layers, and exponentially decay. Therefore, such a model cannot learn well in deeper layers.  \n",
        "\n",
        "Therefore, to prevent vanishing gradients, alternative activation functions such as **ReLU (Rectified Linear Unit)** are used as they keep a gradient of 1 for positive inputs. It also helps when used with **batch normalization** (normalizing layer outputs, reduces the risk of vanishing gradients, and stabilizes training). They allow deeper networks to train better, and those networks to converge faster.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**6)** **ResNet (Residual Networks)** has a **residual connection** that help resolve the **vanishing gradient problem**, allowing the gradient to propagate more effectively in the deep network. In traditional neural networks, small gradients in traditional neural networks can propagate backward through multiple layers and it is hard to train deep architectures. **Skip connections or identity mappings** are introduced by ResNet, which allow the input of a layer to be transported without seeping through an intermediary layer and united with the resulting layer.\n",
        "\n",
        "This shortcut connection allows backprop to strike through certain layers and prevent the gradient from shrinking too much and getting stuck further into layers that are much earlier. We particularly stress this importance in very deep networks, where traditional gradient based optimization approaches face vanishing gradients.\n",
        "\n",
        "They improve **gradient flow**, and even with hundreds or thousands of layers, effectively train the network. As a result, these allow the training of **deeper networks**, obviating the vanishing gradient issue which hinders thebeneficial performance with respect to complex tasks such as image recognition.\n",
        "\n",
        "Finally, by improving the propagation of gradients, Residual connections help mitigate the vanishing gradient problem, permitting us to train deeper neural networks and to perform better learning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OGsx50Qfmhs"
      },
      "source": [
        "# Coding Question Answer\n",
        "\n",
        "**1)** To improve the performance of the LeNet-5 model on the CIFAR-10 dataset, the following modifications were made:\n",
        "Data augmentation: All augmentations such as resize_transform (random cropping and horizontal flipping), improves the data distribution in the training set.\n",
        "Model architecture: To enlarge the capacity of LeNet5 architecture, we change it. Both the number of filters in each convolutional layer increased, and batch normlayers were added after each convolutional layer to make training more stable.\n",
        "Optimizer: Although AdamW optimizer was used instead of the standard Adam, a weight decay of 1e-4 was used in order to provide better regularization.\n",
        "Learning rate scheduler: Therefore, in order to simplify the training, I implemented a stepLR scheduler to decrease the learning rate as the training proceeded, thus facilitating the model fine tuning in later epochs.\n",
        "Dropout: In the classifier part of the network we added a dropout layer with a rate of 0.5 to prevent overfitting.\n",
        "With these modifications, now, the better feature extraction, decreased overfitting and better training resulted in increased accuracy on the CIFAR-10 dataset.\n",
        "\n",
        "\n",
        "---\n",
        "**2)** Test accuracy: 81.01%\n",
        "\n",
        "Experiment logging record for the best model:\n",
        "Data augmentation:\n",
        "Random cropping (32x32 with padding = 4).\n",
        "Random horizontal flipping\n",
        "Scaling (mean = 0.5, standard deviation = 0.5 for every channel)\n",
        "Model architecture:\n",
        "Raised amount of filtering layers in convolutional layers\n",
        "Included BN layer right after every convolution at the model.\n",
        "The classifier has been altered with added fully connected layers and dropout added to the design.\n",
        "Optimizer:\n",
        "AdamW scheduler with a learning rate of 0.001 and weight decay of 1e-4\n",
        "Learning rate scheduler:\n",
        "StepLR with step size schedule 30 and gamma 0.1\n",
        "Training parameters:\n",
        "Batch size: 280\n",
        "Number of epochs: 10\n",
        "These changes provided better identification of the features, controlling the problem of overfitting, better training of the model, which contributed to the achievement of 81.01% accuracy on CIFAR-10 dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORj09gnrj5wp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6hghKPxj5w0"
      },
      "source": [
        "## Model Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnT0sZIwj5wu"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 280\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Architecture\n",
        "NUM_FEATURES = 32*32\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Other\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda:0\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "GRAYSCALE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFBWzfv2BY3"
      },
      "source": [
        "### CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8-y4u8P2BY3",
        "outputId": "545d4d7a-abd7-4060-bc47-fdfd1938b20e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:02<00:00, 85.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Image batch dimensions: torch.Size([280, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([280])\n",
            "Image batch dimensions: torch.Size([280, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([280])\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "### CIFAR-10 Dataset\n",
        "##########################\n",
        "\n",
        "train_mean = (0.5, 0.5, 0.5)\n",
        "train_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "resize_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std)\n",
        "])\n",
        "\n",
        "# Note transforms.ToTensor() scales input images\n",
        "# to 0-1 range\n",
        "train_dataset = datasets.CIFAR10(root='data',\n",
        "                                 train=True,\n",
        "                                 transform=resize_transform,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data',\n",
        "                                train=False,\n",
        "                                transform=resize_transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=8,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=8,\n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgMzBPQ02BY3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ORGq4Dq2BY3",
        "outputId": "7fd434c7-fe6e-4858-fd0b-83db75509310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Batch index: 0 | Batch size: 280\n",
            "Epoch: 2 | Batch index: 0 | Batch size: 280\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(DEVICE)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for epoch in range(2):\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "\n",
        "        print('Epoch:', epoch+1, end='')\n",
        "        print(' | Batch index:', batch_idx, end='')\n",
        "        print(' | Batch size:', y.size()[0])\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI1Oil3q2BY3"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes, grayscale=False):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.grayscale = grayscale\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        if self.grayscale:\n",
        "            in_channels = 1\n",
        "        else:\n",
        "            in_channels = 3\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "    nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2)\n",
        ")\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "    nn.Linear(128 * 8 * 8, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, num_classes)\n",
        ")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lza9t_uj5w1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(NUM_CLASSES, GRAYSCALE)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAodboScj5w6"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzh3ROmRj5w7",
        "outputId": "6c0b4efe-a65d-4101-cbb7-11452bf29d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/020 | Batch 0000/0179 | Cost: 2.2918\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "        features = features.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        logits, probas = model(features)\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "start_time = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits, probas = model(features)\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        cost.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n",
        "                   %(epoch+1, NUM_EPOCHS, batch_idx,\n",
        "                     len(train_loader), cost))\n",
        "\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
        "              epoch+1, NUM_EPOCHS,\n",
        "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "\n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paaeEQHQj5xC"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzQMWKq5j5xE"
      },
      "outputs": [],
      "source": [
        "with torch.set_grad_enabled(False): # save memory during inference\n",
        "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7IycU212BY3"
      },
      "outputs": [],
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        ------------\n",
        "        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "\n",
        "        Returns:\n",
        "        ------------\n",
        "        Tensor: Normalized image.\n",
        "\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "        return tensor\n",
        "\n",
        "unorm = UnNormalize(mean=train_mean, std=train_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA_g0FF92BY3"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(dataset=train_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=True)\n",
        "\n",
        "for features, targets in test_loader:\n",
        "    break\n",
        "\n",
        "\n",
        "_, predictions = model.forward(features[:8].to(DEVICE))\n",
        "predictions = torch.argmax(predictions, dim=1)\n",
        "\n",
        "d = {0: 'airplane',\n",
        "     1: 'automobile',\n",
        "     2: 'bird',\n",
        "     3: 'cat',\n",
        "     4: 'deer',\n",
        "     5: 'dog',\n",
        "     6: 'frog',\n",
        "     7: 'horse',\n",
        "     8: 'ship',\n",
        "     9: 'truck'}\n",
        "\n",
        "fig, ax = plt.subplots(1, 8, figsize=(20, 10))\n",
        "for i in range(8):\n",
        "    img = unorm(features[i])\n",
        "    ax[i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "    ax[i].set_xlabel(d[predictions[i].item()])\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "371px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}